{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4992 images belonging to 5 classes.\n",
      "Found 1248 images belonging to 5 classes.\n",
      "Epoch 1/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 1.6104 - accuracy: 0.1942\n",
      "Epoch 1: val_accuracy improved from -inf to 0.20593, saving model to best_model1.h5\n",
      "156/156 [==============================] - 5s 24ms/step - loss: 1.6104 - accuracy: 0.1939 - val_loss: 1.6092 - val_accuracy: 0.2059\n",
      "Epoch 2/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 1.5632 - accuracy: 0.2585\n",
      "Epoch 2: val_accuracy improved from 0.20593 to 0.31971, saving model to best_model1.h5\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 1.5613 - accuracy: 0.2592 - val_loss: 1.5390 - val_accuracy: 0.3197\n",
      "Epoch 3/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 1.0937 - accuracy: 0.4556\n",
      "Epoch 3: val_accuracy improved from 0.31971 to 0.49038, saving model to best_model1.h5\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 1.0934 - accuracy: 0.4571 - val_loss: 1.3167 - val_accuracy: 0.4904\n",
      "Epoch 4/50\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.9253 - accuracy: 0.5671\n",
      "Epoch 4: val_accuracy improved from 0.49038 to 0.49439, saving model to best_model1.h5\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.9253 - accuracy: 0.5671 - val_loss: 1.4653 - val_accuracy: 0.4944\n",
      "Epoch 5/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.8471 - accuracy: 0.6165\n",
      "Epoch 5: val_accuracy improved from 0.49439 to 0.55128, saving model to best_model1.h5\n",
      "156/156 [==============================] - 4s 23ms/step - loss: 0.8486 - accuracy: 0.6154 - val_loss: 1.3780 - val_accuracy: 0.5513\n",
      "Epoch 6/50\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.7765 - accuracy: 0.6575\n",
      "Epoch 6: val_accuracy did not improve from 0.55128\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.7765 - accuracy: 0.6575 - val_loss: 1.3915 - val_accuracy: 0.5513\n",
      "Epoch 7/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.7472 - accuracy: 0.6658\n",
      "Epoch 7: val_accuracy improved from 0.55128 to 0.56651, saving model to best_model1.h5\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.7467 - accuracy: 0.6665 - val_loss: 1.2156 - val_accuracy: 0.5665\n",
      "Epoch 8/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.7062 - accuracy: 0.6974\n",
      "Epoch 8: val_accuracy improved from 0.56651 to 0.57532, saving model to best_model1.h5\n",
      "156/156 [==============================] - 4s 22ms/step - loss: 0.7081 - accuracy: 0.6975 - val_loss: 1.3226 - val_accuracy: 0.5753\n",
      "Epoch 9/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.6555 - accuracy: 0.7204\n",
      "Epoch 9: val_accuracy did not improve from 0.57532\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.6569 - accuracy: 0.7196 - val_loss: 1.4979 - val_accuracy: 0.5697\n",
      "Epoch 10/50\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.6330 - accuracy: 0.7294\n",
      "Epoch 10: val_accuracy improved from 0.57532 to 0.58093, saving model to best_model1.h5\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.6330 - accuracy: 0.7294 - val_loss: 1.3807 - val_accuracy: 0.5809\n",
      "Epoch 11/50\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.6021 - accuracy: 0.7464\n",
      "Epoch 11: val_accuracy improved from 0.58093 to 0.59535, saving model to best_model1.h5\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.6021 - accuracy: 0.7464 - val_loss: 1.5233 - val_accuracy: 0.5954\n",
      "Epoch 12/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.5673 - accuracy: 0.7646\n",
      "Epoch 12: val_accuracy did not improve from 0.59535\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.5687 - accuracy: 0.7638 - val_loss: 1.5277 - val_accuracy: 0.5697\n",
      "Epoch 13/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.5515 - accuracy: 0.7729\n",
      "Epoch 13: val_accuracy did not improve from 0.59535\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.5535 - accuracy: 0.7712 - val_loss: 1.3771 - val_accuracy: 0.5921\n",
      "Epoch 14/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.5263 - accuracy: 0.7786\n",
      "Epoch 14: val_accuracy did not improve from 0.59535\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.5270 - accuracy: 0.7780 - val_loss: 1.4872 - val_accuracy: 0.5889\n",
      "Epoch 15/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.5140 - accuracy: 0.7881\n",
      "Epoch 15: val_accuracy did not improve from 0.59535\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.5135 - accuracy: 0.7877 - val_loss: 1.3928 - val_accuracy: 0.5938\n",
      "Epoch 16/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.4868 - accuracy: 0.8038\n",
      "Epoch 16: val_accuracy did not improve from 0.59535\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.4864 - accuracy: 0.8035 - val_loss: 1.7867 - val_accuracy: 0.5641\n",
      "Epoch 17/50\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.4494 - accuracy: 0.8167\n",
      "Epoch 17: val_accuracy improved from 0.59535 to 0.61458, saving model to best_model1.h5\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.4494 - accuracy: 0.8167 - val_loss: 1.5302 - val_accuracy: 0.6146\n",
      "Epoch 18/50\n",
      "153/156 [============================>.] - ETA: 0s - loss: 0.4378 - accuracy: 0.8209\n",
      "Epoch 18: val_accuracy improved from 0.61458 to 0.62179, saving model to best_model1.h5\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.4410 - accuracy: 0.8199 - val_loss: 1.6363 - val_accuracy: 0.6218\n",
      "Epoch 19/50\n",
      "155/156 [============================>.] - ETA: 0s - loss: 0.4152 - accuracy: 0.8365\n",
      "Epoch 19: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.4160 - accuracy: 0.8361 - val_loss: 1.4767 - val_accuracy: 0.6002\n",
      "Epoch 20/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8433\n",
      "Epoch 20: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.3897 - accuracy: 0.8421 - val_loss: 1.6743 - val_accuracy: 0.5946\n",
      "Epoch 21/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.3909 - accuracy: 0.8421\n",
      "Epoch 21: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.3908 - accuracy: 0.8417 - val_loss: 1.5154 - val_accuracy: 0.6050\n",
      "Epoch 22/50\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.3497 - accuracy: 0.8590\n",
      "Epoch 22: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.3497 - accuracy: 0.8590 - val_loss: 1.9417 - val_accuracy: 0.5938\n",
      "Epoch 23/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.3353 - accuracy: 0.8681\n",
      "Epoch 23: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.3346 - accuracy: 0.8682 - val_loss: 1.8236 - val_accuracy: 0.5994\n",
      "Epoch 24/50\n",
      "155/156 [============================>.] - ETA: 0s - loss: 0.3210 - accuracy: 0.8748\n",
      "Epoch 24: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.3201 - accuracy: 0.8756 - val_loss: 1.9076 - val_accuracy: 0.5809\n",
      "Epoch 25/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.3063 - accuracy: 0.8787\n",
      "Epoch 25: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.3058 - accuracy: 0.8788 - val_loss: 1.8529 - val_accuracy: 0.5929\n",
      "Epoch 26/50\n",
      "155/156 [============================>.] - ETA: 0s - loss: 0.3018 - accuracy: 0.8819\n",
      "Epoch 26: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.3015 - accuracy: 0.8818 - val_loss: 1.7634 - val_accuracy: 0.5905\n",
      "Epoch 27/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.2735 - accuracy: 0.8973\n",
      "Epoch 27: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.2746 - accuracy: 0.8964 - val_loss: 2.0038 - val_accuracy: 0.5825\n",
      "Epoch 28/50\n",
      "155/156 [============================>.] - ETA: 0s - loss: 0.2634 - accuracy: 0.8948\n",
      "Epoch 28: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.2622 - accuracy: 0.8954 - val_loss: 1.9825 - val_accuracy: 0.5793\n",
      "Epoch 29/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.2323 - accuracy: 0.9109\n",
      "Epoch 29: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.2320 - accuracy: 0.9111 - val_loss: 2.3048 - val_accuracy: 0.5849\n",
      "Epoch 30/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.2483 - accuracy: 0.9065\n",
      "Epoch 30: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.2490 - accuracy: 0.9054 - val_loss: 2.4325 - val_accuracy: 0.5737\n",
      "Epoch 31/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.2253 - accuracy: 0.9127\n",
      "Epoch 31: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.2250 - accuracy: 0.9125 - val_loss: 2.0651 - val_accuracy: 0.5769\n",
      "Epoch 32/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.2249 - accuracy: 0.9148\n",
      "Epoch 32: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.2258 - accuracy: 0.9145 - val_loss: 1.9832 - val_accuracy: 0.5929\n",
      "Epoch 33/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.1903 - accuracy: 0.9265\n",
      "Epoch 33: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.1905 - accuracy: 0.9265 - val_loss: 2.1921 - val_accuracy: 0.5905\n",
      "Epoch 34/50\n",
      "155/156 [============================>.] - ETA: 0s - loss: 0.1973 - accuracy: 0.9286\n",
      "Epoch 34: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.1983 - accuracy: 0.9283 - val_loss: 2.1472 - val_accuracy: 0.6018\n",
      "Epoch 35/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.1945 - accuracy: 0.9257\n",
      "Epoch 35: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.1944 - accuracy: 0.9261 - val_loss: 2.3527 - val_accuracy: 0.5769\n",
      "Epoch 36/50\n",
      "155/156 [============================>.] - ETA: 0s - loss: 0.1923 - accuracy: 0.9262\n",
      "Epoch 36: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.1924 - accuracy: 0.9263 - val_loss: 2.4481 - val_accuracy: 0.5793\n",
      "Epoch 37/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.1708 - accuracy: 0.9359\n",
      "Epoch 37: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.1694 - accuracy: 0.9363 - val_loss: 2.6620 - val_accuracy: 0.5938\n",
      "Epoch 38/50\n",
      "155/156 [============================>.] - ETA: 0s - loss: 0.1588 - accuracy: 0.9462\n",
      "Epoch 38: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.1593 - accuracy: 0.9459 - val_loss: 2.9577 - val_accuracy: 0.5801\n",
      "Epoch 39/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.1645 - accuracy: 0.9420\n",
      "Epoch 39: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.1644 - accuracy: 0.9417 - val_loss: 2.4275 - val_accuracy: 0.5817\n",
      "Epoch 40/50\n",
      "155/156 [============================>.] - ETA: 0s - loss: 0.1469 - accuracy: 0.9470\n",
      "Epoch 40: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.1470 - accuracy: 0.9471 - val_loss: 2.4133 - val_accuracy: 0.6074\n",
      "Epoch 41/50\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1620 - accuracy: 0.9419\n",
      "Epoch 41: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.1620 - accuracy: 0.9419 - val_loss: 2.5455 - val_accuracy: 0.5881\n",
      "Epoch 42/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.1554 - accuracy: 0.9448\n",
      "Epoch 42: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.1554 - accuracy: 0.9445 - val_loss: 2.4712 - val_accuracy: 0.5938\n",
      "Epoch 43/50\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.9451\n",
      "Epoch 43: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.1465 - accuracy: 0.9451 - val_loss: 2.6241 - val_accuracy: 0.5689\n",
      "Epoch 44/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.1414 - accuracy: 0.9458\n",
      "Epoch 44: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.1415 - accuracy: 0.9457 - val_loss: 2.8714 - val_accuracy: 0.5705\n",
      "Epoch 45/50\n",
      "155/156 [============================>.] - ETA: 0s - loss: 0.1338 - accuracy: 0.9478\n",
      "Epoch 45: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.1335 - accuracy: 0.9479 - val_loss: 2.7792 - val_accuracy: 0.5769\n",
      "Epoch 46/50\n",
      "153/156 [============================>.] - ETA: 0s - loss: 0.1308 - accuracy: 0.9555\n",
      "Epoch 46: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.1307 - accuracy: 0.9551 - val_loss: 3.0391 - val_accuracy: 0.5681\n",
      "Epoch 47/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.1439 - accuracy: 0.9511\n",
      "Epoch 47: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.1438 - accuracy: 0.9509 - val_loss: 2.9144 - val_accuracy: 0.5769\n",
      "Epoch 48/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.1226 - accuracy: 0.9547\n",
      "Epoch 48: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.1215 - accuracy: 0.9553 - val_loss: 2.4973 - val_accuracy: 0.5809\n",
      "Epoch 49/50\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9585\n",
      "Epoch 49: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 22ms/step - loss: 0.1139 - accuracy: 0.9585 - val_loss: 3.0059 - val_accuracy: 0.5577\n",
      "Epoch 50/50\n",
      "154/156 [============================>.] - ETA: 0s - loss: 0.1126 - accuracy: 0.9578\n",
      "Epoch 50: val_accuracy did not improve from 0.62179\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 0.1128 - accuracy: 0.9579 - val_loss: 2.7300 - val_accuracy: 0.5753\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 46, 46, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPooli  (None, 23, 23, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, 10, 10, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 4, 4, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 2, 2, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPooli  (None, 1, 1, 256)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421957 (1.61 MB)\n",
      "Trainable params: 421957 (1.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "\n",
    "# Đường dẫn đến thư mục chứa dữ liệu huấn luyện\n",
    "data_dir = 'image'\n",
    "\n",
    "# Kích thước của ảnh (48x48 pixels)\n",
    "img_size = (48, 48)\n",
    "\n",
    "# Tạo đối tượng ImageDataGenerator với tỉ lệ chia là 8:2\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Tạo dữ liệu huấn luyện từ thư mục\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Sử dụng 80% dữ liệu làm tập huấn luyện\n",
    ")\n",
    "\n",
    "# Tạo dữ liệu kiểm thử từ thư mục\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Sử dụng 20% dữ liệu làm tập kiểm thử\n",
    ")\n",
    "\n",
    "# Số lượng lớp\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# Xây dựng mô hình CNN (giống như ví dụ trước)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Dropout(0.75))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))  # Số lớp đầu ra\n",
    "\n",
    "model_checkpoint = callbacks.ModelCheckpoint(\n",
    "    filepath='best_model1.h5',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Compile the model with the new callbacks list\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with the callbacks list\n",
    "history = model.fit(train_generator, epochs=50, validation_data=validation_generator, callbacks=[model_checkpoint])\n",
    "\n",
    "# Load the best model based on validation accuracy\n",
    "best_model = models.load_model('best_model1.h5')\n",
    "\n",
    "# Print information about the best model\n",
    "best_model.summary()\n",
    "\n",
    "# Print the keys of history to access different metrics\n",
    "print(history.history.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1240 images belonging to 5 classes.\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 1.5083 - accuracy: 0.6702\n",
      "Test loss: 1.508269190788269\n",
      "Test accuracy: 0.6701613068580627\n"
     ]
    }
   ],
   "source": [
    "# Import các thư viện cần thiết\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "image_size = 48\n",
    "batch_size = 32\n",
    "# Đọc lại mô hình đã được lưu\n",
    "model = load_model('best_model1.h5')\n",
    "\n",
    "# Đường dẫn đến thư mục chứa dữ liệu kiểm thử\n",
    "test_data_dir = 'C:/Users/Admin/Desktop/train-20240111T182556Z-001/train'\n",
    "\n",
    "# Sử dụng ImageDataGenerator để tạo dữ liệu kiểm thử\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Nếu bạn đang làm việc với nhiều lớp\n",
    "    shuffle=False  # Để giữ thứ tự của các ảnh giống với thứ tự trong thư mục\n",
    ")\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm thử\n",
    "scores = model.evaluate(test_generator)\n",
    "\n",
    "# In ra score cho từng lớp\n",
    "for i in range(len(model.metrics_names)):\n",
    "    print(f\"Test {model.metrics_names[i]}: {scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cnn_model.h5']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(model, 'cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48, 3)\n",
      "(1, 48, 48, 3)\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Predicted label: 2\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model1 = load_model('best_model1.h5')\n",
    "# Đường dẫn đến ảnh bạn muốn dự đoán\n",
    "image_path = \"test.jpeg\"\n",
    "\n",
    "# Load ảnh và chuyển về kích thước và định dạng phù hợp\n",
    "img = image.load_img(image_path, target_size=(48, 48))\n",
    "img_array = image.img_to_array(img)\n",
    "print(img_array.shape)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Thêm một chiều để tạo batch\n",
    "\n",
    "# Chuẩn hóa giá trị pixel về khoảng [0, 1]\n",
    "img_array /= 255.0\n",
    "\n",
    "print(img_array.shape)\n",
    "\n",
    "# Sử dụng mô hình để dự đoán\n",
    "predictions = model1.predict(img_array)\n",
    "\n",
    "# Lấy nhãn có xác suất cao nhất\n",
    "predicted_label = np.argmax(predictions)\n",
    "\n",
    "# Hiển thị kết quả\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.14.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (5.2.0)\n",
      "Requirement already satisfied: fastapi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (0.109.0)\n",
      "Requirement already satisfied: ffmpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (0.3.1)\n",
      "Requirement already satisfied: gradio-client==0.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (0.8.0)\n",
      "Requirement already satisfied: httpx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (0.26.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (0.20.2)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (6.1.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (3.7.2)\n",
      "Requirement already satisfied: numpy~=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (1.26.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (3.9.10)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (23.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (2.0.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (10.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (2.5.3)\n",
      "Requirement already satisfied: pydub in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio) (0.25.0)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio-client==0.8.0->gradio) (2023.12.2)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gradio-client==0.8.0->gradio) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio) (4.20.0)\n",
      "Requirement already satisfied: toolz in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (4.41.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic>=2.0->gradio) (2.14.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
      "Requirement already satisfied: h11>=0.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.36.0,>=0.35.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from fastapi->gradio) (0.35.0)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx->gradio) (4.0.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx->gradio) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx->gradio) (1.0.2)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.31.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.13.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.17.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (1.26.16)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADIO INTERFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Running on local URL:  http://127.0.0.1:7882\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7882/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 1561, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 1179, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\utils.py\", line 678, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14536\\3736386618.py\", line 28, in predict_emotion\n",
      "    img_array = image.img_to_array(img)\n",
      "                ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'numpy.ndarray' object has no attribute 'img_to_array'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 1561, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 1179, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\utils.py\", line 678, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14536\\3736386618.py\", line 28, in predict_emotion\n",
      "    img_array = image.img_to_array(img)\n",
      "                ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'numpy.ndarray' object has no attribute 'img_to_array'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 1561, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 1179, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\utils.py\", line 678, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14536\\3736386618.py\", line 28, in predict_emotion\n",
      "    img_array = image.img_to_array(img)\n",
      "                ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'numpy.ndarray' object has no attribute 'img_to_array'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 1561, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 1179, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\utils.py\", line 678, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14536\\3736386618.py\", line 28, in predict_emotion\n",
      "    img_array = image.img_to_array(img)\n",
      "                ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'numpy.ndarray' object has no attribute 'img_to_array'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from joblib import load\n",
    "import dlib\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('best_model1.h5')\n",
    "\n",
    "emotion_labels = {\n",
    "    0: \"Angry\",\n",
    "    1: \"Fear\",\n",
    "    2: \"Happy\",\n",
    "    3: \"Neutral\",\n",
    "    4: \"Sad\",\n",
    "}\n",
    "\n",
    "# Load dlib's pre-trained face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "def predict_emotion(image):\n",
    "    # Convert Gradio Image to NumPy array\n",
    "    img_array = np.array(image)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    img = Image.fromarray(img_array).resize((48, 48))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add a dimension to create a batch\n",
    "\n",
    "    # Normalize pixel values to the range [0, 1]\n",
    "    img_array /= 255.0\n",
    "\n",
    "    # Make prediction using CNN model\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_label = np.argmax(predictions)\n",
    "\n",
    "    # Detect faces using dlib\n",
    "    faces = detector(img_array[0], 1)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        cropped_face = img_array\n",
    "    else:\n",
    "        # Assuming there's only one face detected, you can modify this if needed\n",
    "        x, y, w, h = faces[0].left(), faces[0].top(), faces[0].width(), faces[0].height()\n",
    "        cropped_face = img_array[:, y:y+h, x:x+w, :]\n",
    "\n",
    "    print(\"Input image shape:\", img_array.shape)\n",
    "    print(\"Processed image shape:\", cropped_face.shape)\n",
    "\n",
    "    return emotion_labels[predicted_label], cropped_face\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_emotion,\n",
    "    inputs=\"image\",\n",
    "    outputs=[\"text\", \"image\"],  \n",
    "    title=\"Emotion Detection\",\n",
    "    description=\"Upload an image and predict the emotion.\"\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
