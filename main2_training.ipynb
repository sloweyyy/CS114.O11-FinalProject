{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skimage import io, color, transform\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = pd.read_csv(\"/Users/lethanhtien/Desktop/run/data/train.csv\")\n",
    "data = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECK CLASS IMBALANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    1250\n",
      "2    1250\n",
      "3    1250\n",
      "4    1250\n",
      "0    1240\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = data['label'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Vẽ biểu đồ cân bằng lớp\n",
    "class_counts.plot(kind='bar', title='Class Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    0.200321\n",
      "2    0.200321\n",
      "3    0.200321\n",
      "4    0.200321\n",
      "0    0.198718\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "total_samples = len(data)\n",
    "class_ratios = class_counts / total_samples\n",
    "print(class_ratios)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x = data.drop(\"label\", axis=1)\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = X_train.values, X_test.values, y_train.values, y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 12,  11,  11, ..., 221, 223, 218], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCALE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo mô hình MinMaxScaler và fit trên tập huấn luyện\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Sử dụng mô hình đã fit để chuẩn hóa tập kiểm tra\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5897435897435898\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# Huấn luyện mô hình SVM với các tham số cụ thể\n",
    "svm_model = SVC(C=0.1, gamma=0.1, kernel='linear', probability=True)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Dự đoán nhãn trên tập kiểm tra\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Đánh giá độ chính xác của mô hình\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5897435897435898\n",
      "\n",
      "Class Angry:\n",
      "  Precision: 0.5451\n",
      "  Recall: 0.5531\n",
      "  F1-Score: 0.5491\n",
      "\n",
      "Class Fear:\n",
      "  Precision: 0.4859\n",
      "  Recall: 0.5105\n",
      "  F1-Score: 0.4979\n",
      "\n",
      "Class Happy:\n",
      "  Precision: 0.7257\n",
      "  Recall: 0.7319\n",
      "  F1-Score: 0.7288\n",
      "\n",
      "Class Neutral:\n",
      "  Precision: 0.7339\n",
      "  Recall: 0.7165\n",
      "  F1-Score: 0.7251\n",
      "\n",
      "Class Sad:\n",
      "  Precision: 0.4641\n",
      "  Recall: 0.4418\n",
      "  F1-Score: 0.4527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Tính precision, recall, và f1-score cho từng lớp\n",
    "precision = precision_score(y_test, y_pred, average=None)\n",
    "recall = recall_score(y_test, y_pred, average=None)\n",
    "f1 = f1_score(y_test, y_pred, average=None)\n",
    "\n",
    "class_names = ['Angry', 'Fear', 'Happy', 'Neutral', 'Sad']\n",
    "\n",
    "# Đánh giá độ chính xác của mô hình\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}\\n')\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    print(f\"Class {class_names[i]}:\")\n",
    "    print(f\"  Precision: {precision[i]:.4f}\")\n",
    "    print(f\"  Recall: {recall[i]:.4f}\")\n",
    "    print(f\"  F1-Score: {f1[i]:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARE WITH OTHERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Cross-validation scores: [0.57357357 0.56256256 0.57114228 0.5741483  0.54609218]\n",
      "Logistic Regression - Mean accuracy: 0.5655037803334396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP - Cross-validation scores: [0.54254254 0.55155155 0.55911824 0.5751503  0.48997996]\n",
      "MLP - Mean accuracy: 0.5436685182176164\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Evaluate each model using cross-validation\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 17\u001b[0m     cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Cross-validation scores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Mean accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(cv_scores)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Evaluate each model using cross-validation\n",
    "for name, model in models.items():\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"{name} - Cross-validation scores: {cv_scores}\")\n",
    "    print(f\"{name} - Mean accuracy: {np.mean(cv_scores)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(path):\n",
    "    # Đường dẫn của tấm ảnh\n",
    "    image_path = path\n",
    "\n",
    "    # Mở ảnh bằng Pillow\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Chuyển ảnh về ảnh trắng đen\n",
    "    img = img.convert(\"L\")\n",
    "\n",
    "    # Chuyển ảnh thành mảng NumPy\n",
    "    img_array = np.array(img)\n",
    "\n",
    "    # Resize ảnh về kích thước mong muốn\n",
    "    resized_img = cv2.resize(img_array, (48, 48))\n",
    "\n",
    "    flattened_img = resized_img.flatten().reshape(-1, 1)\n",
    "    # Use MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    img1 = scaler.fit_transform(flattened_img).T\n",
    "\n",
    "    y_pred = svm_model.predict(img1)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(\"images/fear/fear (151).jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.joblib']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(svm_model, 'svm_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "Accuracy: 0.579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Thiết lập các giá trị thử nghiệm cho C, kernel và gamma\n",
    "param_grid = {'C': [0.1, 1, 10],\n",
    "              'kernel': ['linear', 'rbf'],\n",
    "              'gamma': [0.1, 1, 10]}\n",
    "\n",
    "# Tạo mô hình SVM\n",
    "svm_model = SVC()\n",
    "\n",
    "# Sử dụng GridSearchCV để tìm kiếm qua lưới tham số\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# In ra tham số tốt nhất\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "y_pred = grid_search.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERFACE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image shape: (732, 1024, 3)\n",
      "Processed image shape: (48, 48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py\", line 3095, in fromarray\n",
      "    mode, rawmode = _fromarray_typemap[typekey]\n",
      "                    ~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "KeyError: ((1, 1), '|O')\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 1561, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 1179, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\utils.py\", line 678, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8892\\3529086839.py\", line 25, in predict_emotion\n",
      "    processed_image = Image.fromarray(img_array).convert('L').resize((48, 48))\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py\", line 3098, in fromarray\n",
      "    raise TypeError(msg) from e\n",
      "TypeError: Cannot handle this data type: (1, 1), |O\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image shape: (1239, 1500, 3)\n",
      "Processed image shape: (48, 48)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from joblib import load\n",
    "import dlib\n",
    "\n",
    "svm_model = load('svm_model.h5')\n",
    "\n",
    "emotion_labels = {\n",
    "    0: \"Angry\",\n",
    "    1: \"Fear\",\n",
    "    2: \"Happy\",\n",
    "    3: \"Neutral\",\n",
    "    4: \"Sad\",\n",
    "}\n",
    "\n",
    "# Load dlib's pre-trained face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "def predict_emotion(image):\n",
    "    # Convert Gradio Image to NumPy array\n",
    "    img_array = np.array(image)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    processed_image = Image.fromarray(img_array).convert('L').resize((48, 48))\n",
    "\n",
    "    # Convert to NumPy array\n",
    "    processed_image_array = np.array(processed_image)\n",
    "\n",
    "    # Flatten and reshape\n",
    "    flattened_img = processed_image_array.flatten().reshape(1, -1) / 255.0\n",
    "\n",
    "    # Make prediction using SVM model\n",
    "    prediction = svm_model.predict(flattened_img)[0]\n",
    "\n",
    "    # Detect faces using dlib\n",
    "    faces = detector(img_array, 1)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        cropped_face = img_array\n",
    "    else:\n",
    "        # Assuming there's only one face detected, you can modify this if needed\n",
    "        x, y, w, h = faces[0].left(), faces[0].top(), faces[0].width(), faces[0].height()\n",
    "        cropped_face = img_array[y:y+h, x:x+w]\n",
    "\n",
    "    print(\"Input image shape:\", img_array.shape)\n",
    "    print(\"Processed image shape:\", processed_image_array.shape)\n",
    "\n",
    "    return emotion_labels[prediction], cropped_face\n",
    "\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_emotion,\n",
    "    inputs=\"image\",\n",
    "    outputs=[\"text\", \"image\"],  \n",
    "    live = True,\n",
    "    title=\"Emotion Detection\",\n",
    "    description=\"Upload an image and predict the emotion.\"\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
